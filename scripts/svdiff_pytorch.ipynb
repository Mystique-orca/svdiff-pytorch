{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yZBejXmsmWHp"
      },
      "source": [
        "# SVDiff-pytorch\n",
        "<a href=\"https://colab.research.google.com/github/mkshing/svdiff-pytorch/blob/main/scripts/svdiff_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This is an implementation of [SVDiff: Compact Parameter Space for Diffusion Fine-Tuning](https://arxiv.org/abs/2303.11305) by using dðŸ§¨ffusers. \n",
        "\n",
        "- My summary tweet: https://twitter.com/mk1stats/status/1642865505106272257\n",
        "- Code: https://github.com/mkshing/svdiff-pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS5ixNcIgmOz"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtFrddhZfK0L"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!git clone https://mkshing@github.com/mkshing/svdiff-pytorch.git\n",
        "!pip install -r svdiff-pytorch/requirements.txt\n",
        "!pip install -q -U --pre triton\n",
        "!pip install -q ftfy bitsandbytes==0.35.0 gradio natsort xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8JJNJNRaG1kB"
      },
      "outputs": [],
      "source": [
        "# @markdown **(Optional) Login wandb**<br> If you don't use wandb for logging, make sure to remove `--report_to=\"wandb\"`\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIe4z_vfgsi2"
      },
      "source": [
        "## **Training SVDiff**\n",
        "\n",
        "In this example, use 5 dog images as usual by downloading from [here](https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHf8RTP_MMxg",
        "outputId": "9cfa923d-8c7b-4f94-a13d-353575650dd2"
      },
      "outputs": [],
      "source": [
        "#@title **Dataset**\n",
        "import datetime\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 60))\n",
        "    files = sorted(glob.glob(folder+'/*.jpg'))\n",
        "    for i, file in enumerate(files):\n",
        "        img = Image.open(file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 5, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        name = os.path.basename(file)\n",
        "        ax.set_xlabel(name, fontsize=30)  \n",
        "        fig.tight_layout()             \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# save_image = True #@param {type:\"boolean\"}\n",
        "mount_google_drive = True #@param {type:\"boolean\"}\n",
        "INSTANCE_DATA_DIR = \"/content/drive/MyDrive/AI/dreambooth-dog/data\" #@param {type: 'string'}\n",
        "CLASS_DATA_DIR = \"/content/drive/MyDrive/AI/dreambooth-dog/class-data\" #@param {type: 'string'}\n",
        "OUTPUT_DIR = \"/content/SVDiffOutput\" #@param {type: 'string'}\n",
        "\n",
        "if CLASS_DATA_DIR is None:\n",
        "  CLASS_DATA_DIR = OUTPUT_DIR + \"/class_data_dir\"\n",
        "\n",
        "force_remount = False\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive # type: ignore\n",
        "    try:\n",
        "        drive_path = \"/content/drive\"\n",
        "        drive.mount(drive_path, force_remount=force_remount)\n",
        "        # output_path_gdrive = f\"/content/drive/MyDrive/{save_dir}\"\n",
        "        # save_dir = output_path_gdrive\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "OUTPUT_DIR = os.path.abspath(OUTPUT_DIR)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"INSTANCE_DATA_DIR: {INSTANCE_DATA_DIR}\")\n",
        "print(f\"CLASS_DATA_DIR: {CLASS_DATA_DIR}\")\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S63rQW873HSa"
      },
      "outputs": [],
      "source": [
        "# @title **Parameters:**\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" # @param [\"runwayml/stable-diffusion-v1-5\"]\n",
        "# this is the number nitrosoke recommends \n",
        "NUM_CLASS_IMAGES = 200 #@param {type: \"integer\"}\n",
        "MAX_TRAIN_STEPS = 500 #@param {type: \"integer\"}\n",
        "CHECKPOINTING_STEPS = 200 #@param {type: \"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_a1wDgpQ1bZ",
        "outputId": "013166b6-f379-4f98-94d3-fd9045398b53"
      },
      "outputs": [],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe-GgtnUVO_e"
      },
      "outputs": [],
      "source": [
        "# @title **Train:**\n",
        "! accelerate launch svdiff-pytorch/train_svdiff.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --instance_data_dir=$INSTANCE_DATA_DIR \\\n",
        "  --class_data_dir=$CLASS_DATA_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --instance_prompt=\"photo of a sks dog\" \\\n",
        "  --class_prompt=\"photo of a dog\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-3 \\\n",
        "  --learning_rate_1d=1e-6 \\\n",
        "  --train_text_encoder \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "  --checkpointing_steps=$CHECKPOINTING_STEPS \\\n",
        "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "  --use_8bit_adam \\\n",
        "  --seed=42 \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --gradient_checkpointing \\\n",
        "  # --report_to=\"wandb\" \\\n",
        "  # --revision=\"fp16\" \\\n",
        "  # --mixed_precision=\"fp16\" \\\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4N3IVFyfMFO"
      },
      "source": [
        "### **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown **helper functions**\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "import requests\n",
        "import PIL\n",
        "import torch\n",
        "from torch import autocast\n",
        "import huggingface_hub\n",
        "from transformers import CLIPTextModel\n",
        "from diffusers import (\n",
        "    LMSDiscreteScheduler, \n",
        "    DDIMScheduler, \n",
        "    PNDMScheduler,\n",
        "    DPMSolverMultistepScheduler, \n",
        "    EulerDiscreteScheduler, \n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    StableDiffusionPipeline\n",
        ")\n",
        "from PIL import Image\n",
        "sys.path.append(\"/content/svdiff-pytorch\")\n",
        "from svdiff_pytorch import load_unet_for_svdiff, load_text_encoder_for_svdiff, SCHEDULER_MAPPING, image_grid\n",
        "\n",
        "\n",
        "def load_text_encoder(pretrained_model_name_or_path, spectral_shifts_ckpt, device, fp16=False):\n",
        "    if os.path.isdir(spectral_shifts_ckpt):\n",
        "        spectral_shifts_ckpt = os.path.join(spectral_shifts_ckpt, \"spectral_shifts_te.safetensors\")\n",
        "    elif not os.path.exists(spectral_shifts_ckpt):\n",
        "        # download from hub\n",
        "        hf_hub_kwargs = {} if hf_hub_kwargs is None else hf_hub_kwargs\n",
        "        try:\n",
        "            spectral_shifts_ckpt = huggingface_hub.hf_hub_download(spectral_shifts_ckpt, filename=\"spectral_shifts_te.safetensors\", **hf_hub_kwargs)\n",
        "        except huggingface_hub.utils.EntryNotFoundError:\n",
        "            return CLIPTextModel.from_pretrained(pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=torch.float16 if fp16 else None).to(device)\n",
        "    if not os.path.exists(spectral_shifts_ckpt):\n",
        "            return CLIPTextModel.from_pretrained(pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=torch.float16 if fp16 else None).to(device)\n",
        "    text_encoder = load_text_encoder_for_svdiff(\n",
        "        pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
        "        spectral_shifts_ckpt=spectral_shifts_ckpt,\n",
        "        subfolder=\"text_encoder\", \n",
        "    )\n",
        "    # first perform svd and cache\n",
        "    for module in text_encoder.modules():\n",
        "        if hasattr(module, \"perform_svd\"):\n",
        "            module.perform_svd()\n",
        "    if fp16:\n",
        "        text_encoder = text_encoder.to(device, dtype=torch.float16)\n",
        "    return text_encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pfFRqt_SfN06"
      },
      "outputs": [],
      "source": [
        "# @markdown **Load model:**\n",
        "import sys\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "spectral_shifts_ckpt = \"/content/gal_gadot/v0.2.0/w_train_text_encoder/checkpoint-1000\" #@param {type:\"string\"}\n",
        "scheduler_type = \"dpm_solver++\" #@param [\"ddim\", \"plms\", \"lms\", \"euler\", \"euler_ancestral\", \"dpm_solver++\"]\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "unet = load_unet_for_svdiff(MODEL_NAME, spectral_shifts_ckpt=spectral_shifts_ckpt, subfolder=\"unet\")\n",
        "unet = unet.to(device)\n",
        "for module in unet.modules():\n",
        "  if hasattr(module, \"perform_svd\"):\n",
        "    module.perform_svd()\n",
        "\n",
        "unet = unet.to(device, dtype=torch.float16)\n",
        "text_encoder = load_text_encoder(\n",
        "    pretrained_model_name_or_path=MODEL_NAME, \n",
        "    spectral_shifts_ckpt=spectral_shifts_ckpt, \n",
        "    device=device,\n",
        "    fp16=True,\n",
        ")\n",
        "# load pipe\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    unet=unet,\n",
        "    text_encoder=text_encoder,\n",
        "    vae=AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\"),\n",
        "    requires_safety_checker=False,\n",
        "    safety_checker=None,\n",
        "    feature_extractor=None,\n",
        "    scheduler=SCHEDULER_MAPPING[scheduler_type].from_pretrained(MODEL_NAME, subfolder=\"scheduler\"),\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe = pipe.to(device)\n",
        "print(\"loaded pipeline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "fcf15730e8de421b9f9098122b229a5b",
            "2adfe08548cd4da9badc0a7df2f75717",
            "65944758a4704176bacd496b00de0914",
            "5465c4a7fa804d8784cc520db9356ed4",
            "f994d8360ff8436b8b0180267b8a8bf4",
            "7e20f85aec55456898089e32883cf0d2",
            "14965dfcbc9844a5b53a38c646f7c985",
            "0333d8e7fe2a48b1809b4ee2e62a6789",
            "7ecc62ff24714a9c8e2c12cd52b979f4",
            "cb6e4cbc66fa4da18b01e8086ce4d659",
            "7862951b84a44a50bf70a3eb780f1a31"
          ]
        },
        "id": "gW15FjffdTID",
        "outputId": "08f7efe1-9992-433f-c30b-014dc286c9a4"
      },
      "outputs": [],
      "source": [
        "# @markdown **Run!:**\n",
        "# @markdown <br> *It takes time at the 1st run because SVD is performed. \n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "prompt = \"A picture of a sks dog in a bucket\" #@param {type:\"string\"}\n",
        "num_images_per_prompt = 4 # @param {type: \"integer\"}\n",
        "guidance_scale = 7.5 # @param {type: \"number\"}\n",
        "num_inference_steps = 25 # @param {type: \"integer\"}\n",
        "height = 512 # @param {type: \"integer\"}\n",
        "width = 512 # @param {type: \"integer\"}\n",
        "seed = \"random_seed\" #@param {type:\"string\"}\n",
        "spectral_shifts_scale = 1.0 #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "if pipe.unet.conv_out.scale != spectral_shifts_scale:\n",
        "  for module in pipe.unet.modules():\n",
        "    if hasattr(module, \"set_scale\"):\n",
        "      module.set_scale(scale=spectral_shifts_scale)\n",
        "  print(f\"Set spectral_shifts_scale to {spectral_shifts_scale}!\")\n",
        "  \n",
        "\n",
        "if seed == \"random_seed\":\n",
        "  random.seed()\n",
        "  seed = random.randint(0, 2**32)\n",
        "else:\n",
        "  seed = int(seed)\n",
        "g_cuda = torch.Generator(device='cuda').manual_seed(seed)\n",
        "print(f\"seed: {seed}\")\n",
        "\n",
        "prompts = prompt.split(\"::\")\n",
        "all_images = []\n",
        "for prompt in tqdm(prompts):\n",
        "    with torch.autocast(device), torch.inference_mode():\n",
        "        images = pipe(\n",
        "            prompt,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_images_per_prompt=num_images_per_prompt,\n",
        "            height=height,\n",
        "            width=width,\n",
        "            generator=g_cuda\n",
        "        ).images\n",
        "    all_images.extend(images)\n",
        "grid_image = image_grid(all_images, len(prompts), num_images_per_prompt)\n",
        "grid_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkJ4Gmhjjn5b"
      },
      "source": [
        "### **(Optional) Upload HuggingFace Hub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYY90LQqPfys"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zYK3sawnhgnF"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import create_repo, upload_folder\n",
        "\n",
        "\n",
        "hub_model_id = \"svdiff-library/svdiff_dog_example\" #@param {type: \"string\"}\n",
        "hub_token = \"\" #@param {type: \"string\"}\n",
        "folder_path = \"/content/SVDiffOutput\" #@param {type: \"string\"}\n",
        "\n",
        "if hub_token == \"\":\n",
        "  hub_token = None\n",
        "repo_id = create_repo(repo_id=hub_model_id, exist_ok=True, token=hub_token).repo_id\n",
        "\n",
        "base_model = MODEL_NAME\n",
        "instance_prompt = \"photo of a sks dog\"  #@param {type: \"string\"}\n",
        "# @markdown paste your `instace_prompt` here.\n",
        "\n",
        "yaml = f\"\"\"\n",
        "---\n",
        "license: creativeml-openrail-m\n",
        "base_model: {base_model}\n",
        "instance_prompt: {instance_prompt}\n",
        "tags:\n",
        "- stable-diffusion\n",
        "- stable-diffusion-diffusers\n",
        "- text-to-image\n",
        "- diffusers\n",
        "- svdiff\n",
        "inference: true\n",
        "---\n",
        "\"\"\"\n",
        "model_card = f\"\"\"\n",
        "# SVDiff-pytorch - {repo_id}\n",
        "These are SVDiff weights for {base_model}. The weights were trained on {instance_prompt} using [DreamBooth](https://dreambooth.github.io/).\"\"\"\n",
        "with open(os.path.join(folder_path, \"README.md\"), \"w\") as f:\n",
        "    f.write(yaml + model_card)\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    folder_path=folder_path,\n",
        "    commit_message=\"first commit\",\n",
        "    ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-kPH5whZafS"
      },
      "source": [
        "## **(Optional) Compare with LoRA**\n",
        "\n",
        "In LoRA, the number of trainable parameters is 0.80 M by default. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XOz9flWqZZWa"
      },
      "outputs": [],
      "source": [
        "# @title **LoRA**\n",
        "!accelerate launch svdiff-pytorch/scripts/train_dreambooth_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
        "  --instance_data_dir=\"/content/drive/MyDrive/AI/dreambooth-dog/data\" \\\n",
        "  --class_data_dir=\"/content/drive/MyDrive/AI/dreambooth-dog/class-data\" \\\n",
        "  --output_dir=\"/content/LoRAOutput\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --instance_prompt=\"photo of a sks dog\" \\\n",
        "  --class_prompt=\"photo of a dog\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --checkpointing_steps=100 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=200 \\\n",
        "  --max_train_steps=500 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --gradient_checkpointing \\\n",
        "  --seed 42 \\\n",
        "  --push_to_hub \\\n",
        "  --validation_prompt=\"A photo of sks dog in a bucket\" \\\n",
        "  --validation_epochs=50 \\\n",
        "  --hub_model_id=\"mshing/lora_dreambooth_dog_example\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R5gmQLeKa-oT"
      },
      "outputs": [],
      "source": [
        "# @title **Inference LoRA**\n",
        "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
        "import torch\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "pipe.unet.load_attn_procs(\"/content/LoRAOutput\")\n",
        "image = pipe(\"A picture of a sks dog in a bucket\", num_inference_steps=25).images[0]\n",
        "del pipe\n",
        "torch.cuda.empty_cache()\n",
        "image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AkJ4Gmhjjn5b"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0333d8e7fe2a48b1809b4ee2e62a6789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14965dfcbc9844a5b53a38c646f7c985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2adfe08548cd4da9badc0a7df2f75717": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e20f85aec55456898089e32883cf0d2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_14965dfcbc9844a5b53a38c646f7c985",
            "value": "100%"
          }
        },
        "5465c4a7fa804d8784cc520db9356ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6e4cbc66fa4da18b01e8086ce4d659",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7862951b84a44a50bf70a3eb780f1a31",
            "value": " 25/25 [00:56&lt;00:00,  1.46it/s]"
          }
        },
        "65944758a4704176bacd496b00de0914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0333d8e7fe2a48b1809b4ee2e62a6789",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ecc62ff24714a9c8e2c12cd52b979f4",
            "value": 25
          }
        },
        "7862951b84a44a50bf70a3eb780f1a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e20f85aec55456898089e32883cf0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ecc62ff24714a9c8e2c12cd52b979f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb6e4cbc66fa4da18b01e8086ce4d659": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f994d8360ff8436b8b0180267b8a8bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf15730e8de421b9f9098122b229a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2adfe08548cd4da9badc0a7df2f75717",
              "IPY_MODEL_65944758a4704176bacd496b00de0914",
              "IPY_MODEL_5465c4a7fa804d8784cc520db9356ed4"
            ],
            "layout": "IPY_MODEL_f994d8360ff8436b8b0180267b8a8bf4"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
